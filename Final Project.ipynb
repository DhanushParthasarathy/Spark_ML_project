{
 "cells":[
  {
   "cell_type":"markdown",
   "source":[
    "## **Importing the required libraries**"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"F7jGPS9Fn9pJjSmT68K3PG",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "#Importing all the required libraries for PySpark analysis\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession as ss\n",
    "from pyspark.ml.feature import VectorAssembler as va, StandardScaler as sts, StringIndexer as si\n",
    "from pyspark.ml.regression import LinearRegression as lir\n",
    "from pyspark.ml.evaluation import  RegressionEvaluator as re\n",
    "from pyspark.ml import Pipeline as pl\n",
    "from pyspark.ml.pipeline import PipelineModel as plm"
   ],
   "execution_count":18,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"zsz6zpJtVlFobVy7fr6jln",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## **Starting the Spark Session** "
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"DVZF2QqglrHHuI6Q2WR4kd",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# We start the spark application\n",
    "spark = ss.builder.appName('Final Project').getOrCreate()"
   ],
   "execution_count":2,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"Gok8DY03fub9y8sF8OCmKp",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## **Loading the dataset**"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"pt0XIC2SqucErrTvao8V8I",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "#We first download the data from the website\n",
    "!wget https:\/\/cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud\/IBMSkillsNetwork-BD0231EN-Coursera\/datasets\/NASA_airfoil_noise_raw.csv"
   ],
   "execution_count":3,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "--2024-03-18 14:13:13--  https:\/\/cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud\/IBMSkillsNetwork-BD0231EN-Coursera\/datasets\/NASA_airfoil_noise_raw.csv\r\n",
      "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104\r\n",
      "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 60682 (59K) [text\/csv]\r\n",
      "Saving to: ‘NASA_airfoil_noise_raw.csv’\r\n",
      "\r\n",
      "\r          NASA_airf   0%[                    ]       0  --.-KB\/s               \r         NASA_airfo  92%[=================>  ]  54.61K   257KB\/s               \rNASA_airfoil_noise_ 100%[===================>]  59.26K   278KB\/s    in 0.2s    \r\n",
      "\r\n",
      "2024-03-18 14:13:14 (278 KB\/s) - ‘NASA_airfoil_noise_raw.csv’ saved [60682\/60682]\r\n",
      "\r\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"dMAA4PDE1cBzczEXIohdeu",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "#Now, we load the dataset into the Spark Dataframe\n",
    "df = spark.read.csv('NASA_airfoil_noise_raw.csv', header= True, inferSchema= True)"
   ],
   "execution_count":4,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"RBNkHKSJnHRrrpXvoWKvS5",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "#Let's verify whether the data has been loaded by checking the Schema...\n",
    "df.printSchema()"
   ],
   "execution_count":5,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "root\n",
      " |-- Frequency: integer (nullable = true)\n",
      " |-- AngleOfAttack: double (nullable = true)\n",
      " |-- ChordLength: double (nullable = true)\n",
      " |-- FreeStreamVelocity: double (nullable = true)\n",
      " |-- SuctionSideDisplacement: double (nullable = true)\n",
      " |-- SoundLevel: double (nullable = true)\n",
      "\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"AC5gh0SrXH1lKdq8reilWq",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "#...and by print the top 5 rows of the dataset\n",
    "df.show(5)"
   ],
   "execution_count":6,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "+---------+-------------+-----------+------------------+-----------------------+----------+\n",
      "|Frequency|AngleOfAttack|ChordLength|FreeStreamVelocity|SuctionSideDisplacement|SoundLevel|\n",
      "+---------+-------------+-----------+------------------+-----------------------+----------+\n",
      "|      800|          0.0|     0.3048|              71.3|             0.00266337|   126.201|\n",
      "|     1000|          0.0|     0.3048|              71.3|             0.00266337|   125.201|\n",
      "|     1250|          0.0|     0.3048|              71.3|             0.00266337|   125.951|\n",
      "|     1600|          0.0|     0.3048|              71.3|             0.00266337|   127.591|\n",
      "|     2000|          0.0|     0.3048|              71.3|             0.00266337|   127.461|\n",
      "+---------+-------------+-----------+------------------+-----------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"KByYGYGiJ1GXj70PxOR9u8",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## **Cleaning the dataset**"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"1eG06YQiaQ4dKWjhDZxfqq",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "#Now, let's clean the dataset\n",
    "rowcount1 = df.count()\n",
    "print(rowcount1)"
   ],
   "execution_count":7,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "1522\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"nhR1RDZb5ASfacGeIMV8py",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "#Let's remove duplicate and missing values\n",
    "df = df.dropDuplicates()\n",
    "rowcount2 = df.count()\n",
    "print(rowcount2)\n",
    "df = df.dropna()\n",
    "rowcount3 = df.count()\n",
    "print(rowcount3)"
   ],
   "execution_count":8,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "1503\n",
      "1499\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"fpjUBfm92KjGSpYoMOWx5I",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "#Let's rename the column soundlevel to souundleveldecibels\n",
    "df = df.withColumnRenamed('SoundLevel', 'SoundLevelDecibels')"
   ],
   "execution_count":9,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"g17vWQTcP44ZK856tzUkot",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "#Let's save the cleaned dataframe as parquet fil\n",
    "df.write.mode('overwrite').parquet('NASA_airfoil_noise_cleaned.parquet')"
   ],
   "execution_count":10,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"VP0oLiCVbXnlKezAokmEOL",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "#Let's verify whether all the steps are correct\n",
    "print(\"Part 1 - Evaluation\")\n",
    "\n",
    "print(\"Total rows = \", rowcount1)\n",
    "print(\"Total rows after dropping duplicate rows = \", rowcount2)\n",
    "print(\"Total rows after dropping duplicate rows and rows with null values = \", rowcount3)\n",
    "print(\"New column name = \", df.columns[-1])\n",
    "\n",
    "import os\n",
    "\n",
    "print(\"NASA_airfoil_noise_cleaned.parquet exists :\", os.path.isdir(\"NASA_airfoil_noise_cleaned.parquet\"))"
   ],
   "execution_count":12,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Part 1 - Evaluation\n",
      "Total rows =  1522\n",
      "Total rows after dropping duplicate rows =  1503\n",
      "Total rows after dropping duplicate rows and rows with null values =  1499\n",
      "New column name =  SoundLevelDecibels\n",
      "NASA_airfoil_noise_cleaned.parquet exists : True\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"K9gQKxPle3QAr6TuQCAW6g",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## **Creating a ML Pipeline**"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"ynDSs5mQi49n6I0nWxutAC",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "#Let's load the dataset from the parquet file\n",
    "df = spark.read.parquet('NASA_airfoil_noise_cleaned.parquet', header= True, inferSchema= True)\n",
    "rowcount4 = df.count() #To verify whether the dataset has been loaded properly. Should be equal to rowcount3\n",
    "df.printSchema()"
   ],
   "execution_count":14,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "root\n",
      " |-- Frequency: integer (nullable = true)\n",
      " |-- AngleOfAttack: double (nullable = true)\n",
      " |-- ChordLength: double (nullable = true)\n",
      " |-- FreeStreamVelocity: double (nullable = true)\n",
      " |-- SuctionSideDisplacement: double (nullable = true)\n",
      " |-- SoundLevelDecibels: double (nullable = true)\n",
      "\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"vsC1PKV2UTTWz5aqIvVJcO",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "#Let's create the stages of the pipeline\n",
    "vector = va(inputCols=['Frequency', 'AngleOfAttack', 'ChordLength', 'FreeStreamVelocity', 'SuctionSideDisplacement'], outputCol='features')\n",
    "scaler = sts(inputCol='features', outputCol='scaledFeatures')\n",
    "lr = lir(labelCol='SoundLevelDecibels', featuresCol= 'scaledFeatures')"
   ],
   "execution_count":15,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"SCZK0m7jOmZVET0n2B9Zs2",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "#Let's create the pipeline\n",
    "pipe = pl(stages= [vector, scaler, lr])"
   ],
   "execution_count":19,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"EGjpuBRuvecjNFHtCAyFFU",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "#Let's split the dataset for training and testing\n",
    "(training_data, test_data) = df.randomSplit([0.7, 0.3], seed=42)"
   ],
   "execution_count":20,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"TpWmpPyLrX8SooC3TpBYZk",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Let's create the model and fit our data\n",
    "pipelineModel = pipe.fit(training_data)"
   ],
   "execution_count":21,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"KKCAPAPr0nvPEEbsIuihc9",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "#Let's verify the steps are correct\n",
    "print(\"Part 2 - Evaluation\")\n",
    "print(\"Total rows = \", rowcount4)\n",
    "ps = [str(x).split(\"_\")[0] for x in pipe.getStages()]\n",
    "\n",
    "print(\"Pipeline Stage 1 = \", ps[0])\n",
    "print(\"Pipeline Stage 2 = \", ps[1])\n",
    "print(\"Pipeline Stage 3 = \", ps[2])\n",
    "\n",
    "print(\"Label column = \", lr.getLabelCol())"
   ],
   "execution_count":23,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Part 2 - Evaluation\n",
      "Total rows =  1499\n",
      "Pipeline Stage 1 =  VectorAssembler\n",
      "Pipeline Stage 2 =  StandardScaler\n",
      "Pipeline Stage 3 =  LinearRegression\n",
      "Label column =  SoundLevelDecibels\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"rTfJywELq1RmIzUkWEtPmS",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## **Model Evaluation**"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"wtsaIHM1f2CDSGs5ry8YGO",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "#Now, let's evaluate our model\n",
    "predictions = pipelineModel.transform(test_data)"
   ],
   "execution_count":24,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"Zus42bTzoU8IDVT0XZtpBW",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "#Let's calculate Mean Squared Error\n",
    "evaluator = re(labelCol= 'SoundLevelDecibels', predictionCol= 'prediction', metricName= 'mse')\n",
    "mse = evaluator.evaluate(predictions)\n",
    "print('Mean Squared Error:', mse)"
   ],
   "execution_count":26,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Mean Squared Error: 24.99766625502418\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"4qGzkcnwQ2KTmBxFHSanl2",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "#Let's calculate Mean Absolute Error\n",
    "evaluator = re(labelCol= 'SoundLevelDecibels', predictionCol= 'prediction', metricName= 'mae')\n",
    "mae = evaluator.evaluate(predictions)\n",
    "print('Mean Absolute Error:', mae)"
   ],
   "execution_count":27,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Mean Absolute Error: 3.9136790958812044\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"T58WufKkxTrdv4Iz4WOaVX",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "#Let's calculate R Squared\n",
    "evaluator = re(labelCol= 'SoundLevelDecibels', predictionCol= 'prediction', metricName= 'r2')\n",
    "r2 = evaluator.evaluate(predictions)\n",
    "print('R Squared:', r2)"
   ],
   "execution_count":28,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "R Squared: 0.4959688408974623\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"XBtWHEzsGiU2mVBPbOkeAK",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "#Let's verify the steps \n",
    "print(\"Part 3 - Evaluation\")\n",
    "\n",
    "print(\"Mean Squared Error = \", round(mse,2))\n",
    "print(\"Mean Absolute Error = \", round(mae,2))\n",
    "print(\"R Squared = \", round(r2,2))\n",
    "\n",
    "lrModel = pipelineModel.stages[-1]\n",
    "\n",
    "print(\"Intercept = \", round(lrModel.intercept,2))"
   ],
   "execution_count":29,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Part 3 - Evaluation\n",
      "Mean Squared Error =  25.0\n",
      "Mean Absolute Error =  3.91\n",
      "R Squared =  0.5\n",
      "Intercept =  132.88\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"HCgPQiLkkAYQ87ekOpywVm",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## **Model Persistence**"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"876bDYg5hpP4CSqjoXaaKY",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "#Let's save the model\n",
    "pipelineModel.write().overwrite().save('.\/Final_Project\/')"
   ],
   "execution_count":30,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"FAawWDXFE88Khm5AI7YzrJ",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "#Let's load the model \n",
    "loadedpipelineModel = pipelineModel.load('Final_Project')"
   ],
   "execution_count":31,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"jStEVga0oV3flKxHZ8kJY1",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "#Let's predict using the load model\n",
    "predictions_new = loadedpipelineModel.transform(test_data)\n",
    "predictions_new.select('prediction').show()"
   ],
   "execution_count":32,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "+------------------+\n",
      "|        prediction|\n",
      "+------------------+\n",
      "|122.59722914376778|\n",
      "|127.37968204568838|\n",
      "|130.34077425074506|\n",
      "|131.11016975113537|\n",
      "|127.12627360125096|\n",
      "|127.89456373905155|\n",
      "|131.06220981224084|\n",
      "|125.73739953848445|\n",
      "|121.53249832197925|\n",
      "|124.20059665619313|\n",
      "|125.87997778533571|\n",
      "|125.24362112904095|\n",
      "|126.06429872612995|\n",
      "|127.67830278943778|\n",
      "|121.25022147564815|\n",
      "|123.31966959832609|\n",
      "|124.20046348885936|\n",
      "| 126.1606883964179|\n",
      "|122.53378592206057|\n",
      "|123.42922049990014|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"gPFzfuo1RxB8YoY2Lv2J0o",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "#Let's verify the steps\n",
    "print(\"Part 4 - Evaluation\")\n",
    "\n",
    "loadedmodel = loadedpipelineModel.stages[-1]\n",
    "totalstages = len(loadedpipelineModel.stages)\n",
    "inputcolumns = loadedpipelineModel.stages[0].getInputCols()\n",
    "\n",
    "print(\"Number of stages in the pipeline = \", totalstages)\n",
    "for i,j in zip(inputcolumns, loadedmodel.coefficients):\n",
    "    print(f\"Coefficient for {i} is {round(j,4)}\")"
   ],
   "execution_count":33,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Part 4 - Evaluation\n",
      "Number of stages in the pipeline =  3\n",
      "Coefficient for Frequency is -3.9906\n",
      "Coefficient for AngleOfAttack is -2.2881\n",
      "Coefficient for ChordLength is -3.3269\n",
      "Coefficient for FreeStreamVelocity is 1.4832\n",
      "Coefficient for SuctionSideDisplacement is -2.0551\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"QMMq45xeAsqSoljeRT0WxP",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## **Stop the session**"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"IXlo8aVC1Jkb1Mf55QnbIs",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "spark.stop()"
   ],
   "execution_count":34,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"0FgswB4plWqEeVRoIdSOEL",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  }
 ],
 "metadata":{
  "kernelspec":{
   "display_name":"Python",
   "language":"python",
   "name":"python"
  },
  "datalore":{
   "computation_mode":"JUPYTER",
   "package_manager":"pip",
   "base_environment":"default",
   "packages":[
    {
     "name":"findspark",
     "version":"2.0.1",
     "source":"PIP"
    }
   ],
   "report_row_ids":[
    
   ],
   "version":3
  }
 },
 "nbformat":4,
 "nbformat_minor":4
}